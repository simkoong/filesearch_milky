from google import genai
from google.genai import types

from .config import GOOGLE_API_KEY, FILE_SEARCH_STORE_NAME, GEMINI_MODEL

# Milky ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•„ìš”í•˜ë©´ ê³„ì† ë‹¤ë“¬ì–´ë„ ë¨)
MILKY_SYSTEM_PROMPT = """
ë„ˆì˜ ì´ë¦„ì€ ë°€í‚¤(Milky)ì´ê³ , ì†Œëª¨ì„ ì•„ì´ì˜¨(AION)ì—ì„œ Gemini File search ì‹œí˜„ì„ ìœ„í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. 

ì—­í• :
1. ì‚¬ìš©ìì˜ ë¬¸ì„œ(íŒŒì¼ ê²€ìƒ‰ ê²°ê³¼)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœëŒ€í•œ ì •í™•í•˜ê²Œ ì„¤ëª…í•œë‹¤.
2. ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ ë¬¸ì„œë¥¼ ìµœìš°ì„  ê·¼ê±°ë¡œ ì‚¼ê³ , ë¬¸ì„œ ë‚´ìš©ê³¼ ì¶”ë¡ ì„ ëª…í™•íˆ êµ¬ë¶„í•œë‹¤.
3. ëª¨ë¥´ë©´ ì•„ëŠ” ì²™í•˜ì§€ ë§ê³ , "ë¬¸ì„œ ë²”ìœ„ ë‚´ì—ì„œëŠ” í™•ì¸ë˜ì§€ ì•ŠëŠ”ë‹¤"ë¼ê³  ì†”ì§íˆ ë§í•œë‹¤.
4. í‘œí˜„ì€ ì¹œì ˆí•˜ê³ , ê°€ë” ê³ ì–‘ì´ ë§íˆ¬(ì˜ˆ: ~í•´ìš”, ~ì¢‹ê² ì–´ìš”, ì‚´ì§ ê·€ì—½ê²Œ)ë¥¼ ì„ë˜
   ì „ë¬¸ì„±ì€ ì ˆëŒ€ ë–¨ì–´ëœ¨ë¦¬ì§€ ì•ŠëŠ”ë‹¤.

ì£¼ì˜:
- ì‹¤ì œ ë²•ë¥ Â·ê·œì • í•´ì„ì€ ì°¸ê³ ìš©ì¼ ë¿, ìµœì¢… ì˜ì‚¬ê²°ì •ì€ í•­ìƒ ê´€ë ¨ ë¶€ì„œ/ì „ë¬¸ê°€ í™•ì¸ì´ í•„ìš”í•¨ì„
  ë¶€ë“œëŸ½ê²Œ í•œ ì¤„ ì •ë„ ë§ë¶™ì¸ë‹¤.
"""

# Google GenAI í´ë¼ì´ì–¸íŠ¸ (í”„ë¡œì„¸ìŠ¤ ë‹¨ìœ„ 1ê°œë§Œ)
_client = genai.Client(api_key=GOOGLE_API_KEY)


def ask_milky_rag(question: str) -> str:
    """
    File Search Storeë¥¼ ë„êµ¬ë¡œ ì‚¬ìš©í•˜ëŠ” Milky RAG í˜¸ì¶œ í•¨ìˆ˜.
    """
    file_search_tool = types.Tool(
        file_search=types.FileSearch(
            file_search_store_names=[FILE_SEARCH_STORE_NAME]
        )
    )

    resp = _client.models.generate_content(
        model=GEMINI_MODEL,
        contents=question,
        config=types.GenerateContentConfig(
            tools=[file_search_tool],
            system_instruction=MILKY_SYSTEM_PROMPT,
        ),
    )

    # ê¸°ë³¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    answer = resp.text or ""
    
    # ì‹¤ì œ ì°¸ê³ í•œ ë¬¸ì„œ ì¶”ì¶œ (grounding_metadata ì‚¬ìš©)
    referenced_docs = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ set ì‚¬ìš©
    
    if hasattr(resp, "candidates") and resp.candidates:
        for cand in resp.candidates:
            # grounding_metadataì—ì„œ ì‹¤ì œ ì°¸ê³  ë¬¸ì„œ ì¶”ì¶œ
            if hasattr(cand, "grounding_metadata") and cand.grounding_metadata:
                gm = cand.grounding_metadata
                if hasattr(gm, "grounding_chunks") and gm.grounding_chunks:
                    for chunk in gm.grounding_chunks:
                        # retrieved_contextì— document_nameì´ ìˆìœ¼ë©´ ì¶”ì¶œ
                        if hasattr(chunk, "retrieved_context") and chunk.retrieved_context:
                            rc = chunk.retrieved_context
                            # document_name ë˜ëŠ” title ì‚¬ìš©
                            doc_name = getattr(rc, "title", None) or getattr(rc, "document_name", None)
                            if doc_name:
                                referenced_docs.add(doc_name)
    
    # ì°¸ê³  ë¬¸ì„œê°€ ìˆìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì¶”ê°€
    if referenced_docs:
        citation_md = "\n\n**ğŸ“š ì°¸ê³  ë¬¸ì„œ**\n"
        for doc_name in sorted(referenced_docs):  # ì •ë ¬í•´ì„œ í‘œì‹œ
            citation_md += f"- {doc_name}\n"
        answer = answer.strip() + citation_md
    
    return answer.strip()

